{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRT Parallel Processing\n",
    "\n",
    "In this notebook we will test the parallel processing for GRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two lines are very important for getting the code working as expected in a multicore machine.  Since numpy uses OpenMP to compute matricial operations, the program normally spawns child processes to perform those operations.  As a result if you use multiprocessing (mp), besides the processes retrieved by mp, it will start 4 NP processes.  To avoid this, you just need to set this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gravray import *\n",
    "from gravray.util import *\n",
    "from gravray.sampling import *\n",
    "from gravray.spice import *\n",
    "from gravray.orbit import *\n",
    "from gravray.stats import *\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from itertools import product as cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available number of processors:  3\n"
     ]
    }
   ],
   "source": [
    "Spice.loadKernels()\n",
    "NP=mp.cpu_count()-1\n",
    "print(\"Available number of processors: \",NP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "body=\"EARTH\"\n",
    "earth=Body(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NRAYS=0\n",
    "def rayProcessing(initial,nw=0):\n",
    "    global NRAYS\n",
    "    t=initial[0]\n",
    "    site=initial[1]\n",
    "    direction=initial[2]\n",
    "    ray=GrtRay(site,direction[0][0],direction[0][1],direction[1])\n",
    "    ray.updateRay(t)\n",
    "    try:\n",
    "        ray.propagateRay(t)\n",
    "        #detJ=ray.calcJacobianDeterminant()\n",
    "        detJ=1\n",
    "    except AssertionError as e:\n",
    "        detJ=0\n",
    "    raydf=ray.packRay()\n",
    "    raydf[\"detJ\"]=detJ\n",
    "    del ray\n",
    "    NRAYS+=1\n",
    "    if (NRAYS%10000)==1:\n",
    "        unreachable=gc.collect()\n",
    "        print(f\"Completed rays by worker {nw}: {NRAYS} (unreachable {unreachable})\")\n",
    "        elTime(start=True)\n",
    "    return raydf\n",
    "    \n",
    "def rayProcessingMulti(initials,nw=0):\n",
    "    print(f\"Processing {len(initials)} initial conditions in worker {nw}\")\n",
    "    raydfs=[rayProcessing(initial) for initial in initials]\n",
    "    return raydfs\n",
    "\n",
    "allrays=pd.DataFrame()\n",
    "def joinResults(raydfs):\n",
    "    global allrays\n",
    "    allrays=pd.concat((allrays,)+tuple(raydfs))\n",
    "    del raydfs\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 initial conditions in worker 0\n",
      "Completed rays by worker 0: 1 (unreachable 7)\n",
      "Elapsed time since script start: 3.94697 min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[            et   lon   lat      alt      A     h        v          ximp  \\\n",
       " 0  414170434.0  61.1  54.8  23300.0  101.1  15.9 -18600.0 -1.232675e+11   \n",
       " \n",
       "            yimp          zimp  ...       vzhel         q         e         i  \\\n",
       " 0  8.134799e+10 -3.528140e+06  ...  -2274.5822  0.738582  0.549668  4.041579   \n",
       " \n",
       "             W          w          M         a             n  detJ  \n",
       " 0  326.572556  106.86342  21.323547  1.640082  9.479146e-08     1  \n",
       " \n",
       " [1 rows x 28 columns]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts=[Spice.str2t(\"02/15/2013 03:20:34 UTC\")]\n",
    "siteprops=[[61.1*Angle.Deg,54.8*Angle.Deg,23.3*Const.km]]\n",
    "sites=[]\n",
    "for siteprop in siteprops:\n",
    "    sites+=[Location(earth,siteprop[0],siteprop[1],siteprop[2])]\n",
    "directions=[[[101.1*Angle.Deg,15.9*Angle.Deg],-18.6*Const.km/Const.s]]\n",
    "\n",
    "#List of conditions\n",
    "initials=list(cartesian(*[ts,sites,directions]))\n",
    "rayProcessingMulti(initials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massive input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing times...\n",
      "Preparing sites...\n",
      "Elapsed time since last call: 1.80292 ms\n",
      "Preparing directions...\n",
      "Elapsed time since last call: 628.233 us\n",
      "Preparing initial conditions...\n",
      "Elapsed time since last call: 88.6917 us\n",
      "Number of initial conditions: 80 = 10(ts)*2(sites)*4(dirs)\n"
     ]
    }
   ],
   "source": [
    "#Numbers\n",
    "Ntimes=Nsites=Npoints=Nvels=10\n",
    "\"\"\"\n",
    "Ntimes=365\n",
    "Nsites=100\n",
    "Npoints=100\n",
    "Nvels=50\n",
    "#\"\"\"\n",
    "\n",
    "#Times\n",
    "print(\"Preparing times...\")\n",
    "tini=Spice.str2t(\"02/15/2013 03:20:34\")\n",
    "tend=tini+Const.Year\n",
    "ts=np.linspace(tini,tend,10)\n",
    "\n",
    "#Sites\n",
    "print(\"Preparing sites...\")\n",
    "elTime(0)\n",
    "H=23.3*Const.km\n",
    "points=Sample(Nsites)\n",
    "points.genUnitSphere()\n",
    "siteprops=np.zeros((Nsites,3))\n",
    "siteprops[:,:2]=points.pp[:,1:]\n",
    "siteprops[:,2]=H*np.ones(Nsites)\n",
    "sites=[]\n",
    "for siteprop in siteprops:\n",
    "    sites+=[Location(earth,siteprop[0],siteprop[1],siteprop[2])]\n",
    "elTime()\n",
    "\n",
    "#Directions\n",
    "print(\"Preparing directions...\")\n",
    "elTime(0)\n",
    "gpoints=Sample(Npoints)\n",
    "gpoints.genUnitHemisphere()\n",
    "speeds=-np.linspace(11.2,72.0,Nvels)*Const.km/Const.s\n",
    "directions=list(cartesian(*[gpoints.pp[:,1:].tolist(),speeds]))\n",
    "elTime()\n",
    "\n",
    "#Initial conditions\n",
    "print(\"Preparing initial conditions...\")\n",
    "elTime(0)\n",
    "initials=list(cartesian(*[ts,sites,directions]))\n",
    "elTime()\n",
    "\n",
    "Ninitials=len(initials)\n",
    "print(f\"Number of initial conditions: {Ninitials} = {len(ts)}(ts)*{len(sites)}(sites)*{len(directions)}(dirs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking and computing time estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential processing of 80 rays:\n",
      "Processing 10 initial conditions in worker 0\n",
      "Elapsed time since last call: 57.2081 ms\n",
      "Total duration: 57.20806121826172 ms, Duration per ray: 5.720806121826172 ms\n",
      "3 chunks containing 27 initial conditions\n",
      "\n",
      "Estimated total: 457.66448974609375 ms\n",
      "Estimated time per chunk (estimated parallel): 154.46176528930664 ms\n"
     ]
    }
   ],
   "source": [
    "#Computing time estimations\n",
    "print(f\"Sequential processing of {Ninitials} rays:\")\n",
    "dt,dtu=elTime(0)\n",
    "tinitials=initials[:10]\n",
    "rays=rayProcessingMulti(tinitials)\n",
    "dt,dtu=elTime()\n",
    "tpray=dt/len(tinitials)\n",
    "tupray=tUnit(tpray)\n",
    "totrays=tpray*Ninitials\n",
    "toturays=tUnit(totrays)\n",
    "print(f\"Total duration: {dtu[0]} {dtu[1]}, Duration per ray: {tupray[0]} {tupray[1]}\")\n",
    "\n",
    "#Chunks\n",
    "npchunk=np.int(np.ceil(Ninitials/NP))\n",
    "cinitials=[initial for initial in Util.chunkList(initials,npchunk)]\n",
    "Nchunks=len(cinitials)\n",
    "print(f\"{Nchunks} chunks containing {npchunk} initial conditions\")\n",
    "tchunk=tpray*npchunk\n",
    "tchunku=tUnit(tchunk)\n",
    "print()\n",
    "print(f\"Estimated total: {toturays[0]} {toturays[1]}\")\n",
    "print(f\"Estimated time per chunk (estimated parallel): {tchunku[0]} {tchunku[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 27 initial conditions in worker 0\n",
      "Processing 27 initial conditions in worker 1\n",
      "Processing 26 initial conditions in worker 2\n",
      "Elapsed time since last call: 445.189 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4451887607574463, [445.1887607574463, 'ms'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allrays=pd.DataFrame()\n",
    "pool=mp.Pool(processes=NP)\n",
    "elTime(0)\n",
    "[pool.apply_async(rayProcessingMulti,args=(inis,nw),callback=joinResults) for nw,inis in enumerate(cinitials)]\n",
    "pool.close()\n",
    "pool.join()\n",
    "elTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results: 80\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of results:\",len(allrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allrays.to_csv(\"rays_parallel.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
