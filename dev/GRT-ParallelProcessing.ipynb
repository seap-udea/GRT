{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRT Parallel Processing\n",
    "\n",
    "In this notebook we will test the parallel processing for GRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('FILE=\"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('FILE=\"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('FILE=\"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('FILE=\"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('FILE=\"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('FILE=\"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from gravray import *\n",
    "from gravray.util import *\n",
    "from gravray.sampling import *\n",
    "from gravray.spice import *\n",
    "from gravray.orbit import *\n",
    "from gravray.stats import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from itertools import product as cartesian\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):yield l[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  4\n"
     ]
    }
   ],
   "source": [
    "Spice.loadKernels()\n",
    "NP=mp.cpu_count()\n",
    "print(\"Number of processors: \",NP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "body=\"EARTH\"\n",
    "earth=Body(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rayProcessing(initial):\n",
    "    t=initial[0]\n",
    "    site=initial[1]\n",
    "    direction=initial[2]\n",
    "    ray=GrtRay(site,direction[0][0],direction[0][1],direction[1])\n",
    "    ray.updateRay(t)\n",
    "    try:\n",
    "        ray.propagateRay(t)\n",
    "        detJ=ray.calcJacobianDeterminant()\n",
    "    except AssertionError as e:\n",
    "        detJ=0\n",
    "    raydf=ray.packRay()\n",
    "    raydf[\"detJ\"]=detJ\n",
    "    return raydf\n",
    "    \n",
    "def rayProcessingMulti(initials):\n",
    "    print(f\"Processing {len(initials)} initial conditions\")\n",
    "    raydfs=[rayProcessing(initial) for initial in initials]\n",
    "    return raydfs\n",
    "\n",
    "allrays=pd.DataFrame()\n",
    "def joinResults(raydfs):\n",
    "    global allrays\n",
    "    allrays=pd.concat((allrays,)+tuple(raydfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts=[Spice.str2t(\"02/15/2013 03:20:34 UTC\")]\n",
    "siteprops=[[61.1*Angle.Deg,54.8*Angle.Deg,23.3*Const.km]]\n",
    "sites=[]\n",
    "for siteprop in siteprops:\n",
    "    sites+=[Location(earth,siteprop[0],siteprop[1],siteprop[2])]\n",
    "directions=[[[101.1*Angle.Deg,15.9*Angle.Deg],-18.6*Const.km/Const.s]]\n",
    "\n",
    "#List of conditions\n",
    "initials=list(cartesian(*[ts,sites,directions]))\n",
    "rayProcessingMulti(initials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massive input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numbers\n",
    "Ntimes=Nsites=Npoints=Nvels=5\n",
    "\n",
    "#Times\n",
    "print(\"Preparing times...\")\n",
    "tini=Spice.str2t(\"02/15/2013 03:20:34\")\n",
    "tend=tini+Const.Year\n",
    "ts=np.linspace(tini,tend,10)\n",
    "\n",
    "#Sites\n",
    "print(\"Preparing sites...\")\n",
    "elTime(0)\n",
    "H=23.3*Const.km\n",
    "points=Sample(Nsites)\n",
    "points.genUnitSphere()\n",
    "siteprops=np.zeros((Nsites,3))\n",
    "siteprops[:,:2]=points.pp[:,1:]\n",
    "siteprops[:,2]=H*np.ones(Nsites)\n",
    "sites=[]\n",
    "for siteprop in siteprops:\n",
    "    sites+=[Location(earth,siteprop[0],siteprop[1],siteprop[2])]\n",
    "elTime()\n",
    "\n",
    "#Directions\n",
    "print(\"Preparing directions...\")\n",
    "elTime(0)\n",
    "gpoints=Sample(Npoints)\n",
    "gpoints.genUnitHemisphere()\n",
    "speeds=-np.linspace(11.2,72.0,Nvels)*Const.km/Const.s\n",
    "directions=list(cartesian(*[gpoints.pp[:,1:].tolist(),speeds]))\n",
    "elTime()\n",
    "\n",
    "#Initial conditions\n",
    "print(\"Preparing initial conditions...\")\n",
    "elTime(0)\n",
    "initials=list(cartesian(*[ts,sites,directions]))\n",
    "elTime()\n",
    "\n",
    "Ninitials=len(initials)\n",
    "print(f\"Number of initial conditions: {Ninitials} = {len(ts)}(ts)*{len(sites)}(sites)*{len(directions)}(dirs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking and computing time estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing time estimations\n",
    "print(f\"Sequential processing of {Ninitials} rays:\")\n",
    "dt,dtu=elTime(0)\n",
    "tinitials=initials[:10]\n",
    "rays=rayProcessingMulti(tinitials)\n",
    "dt,dtu=elTime()\n",
    "tpray=dt/len(tinitials)\n",
    "tupray=tUnit(tpray)\n",
    "totrays=tpray*Ninitials\n",
    "toturays=tUnit(totrays)\n",
    "print(f\"Total duration: {dtu[0]} {dtu[1]}, Duration per ray: {tupray[0]} {tupray[1]}\")\n",
    "\n",
    "#Chunks\n",
    "npchunk=np.int(np.ceil(Ninitials/NP))\n",
    "cinitials=[initial for initial in chunks(initials,npchunk)]\n",
    "Nchunks=len(cinitials)\n",
    "print(f\"{Nchunks} chunks containing {npchunk} initial conditions\")\n",
    "tchunk=tpray*npchunk\n",
    "tchunku=tUnit(tchunk)\n",
    "print()\n",
    "print(f\"Estimated total: {toturays[0]} {toturays[1]}\")\n",
    "print(f\"Estimated time per chunk (estimated parallel): {tchunku[0]} {tchunku[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allrays=pd.DataFrame()\n",
    "pool=mp.Pool(processes=NP,maxtasksperchild=1)\n",
    "elTime(0)\n",
    "[pool.apply_async(rayProcessingMulti,args=(inis,),callback=joinResults) for inis in cinitials]\n",
    "pool.close()\n",
    "pool.join()\n",
    "elTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of results:\",len(allrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allrays.to_csv(\"rays_parallel.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
