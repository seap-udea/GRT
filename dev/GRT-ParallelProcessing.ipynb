{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRT Parallel Processing\n",
    "\n",
    "In this notebook we will test the parallel processing for GRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two lines are very important for getting the code working as expected in a multicore machine.  Since numpy uses OpenMP to compute matricial operations, the program normally spawns child processes to perform those operations.  As a result if you use multiprocessing (mp), besides the processes retrieved by mp, it will start 4 NP processes.  To avoid this, you just need to set this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('FILE=\"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('FILE=\"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('FILE=\"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('FILE=\"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('FILE=\"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.kernel.execute('FILE=\"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from gravray import *\n",
    "from gravray.util import *\n",
    "from gravray.sampling import *\n",
    "from gravray.spice import *\n",
    "from gravray.orbit import *\n",
    "from gravray.stats import *\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from itertools import product as cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available number of processors:  3\n"
     ]
    }
   ],
   "source": [
    "Spice.loadKernels()\n",
    "NP=mp.cpu_count()-1\n",
    "print(\"Available number of processors: \",NP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyid=\"EARTH\"\n",
    "body=Body(bodyid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NRAYS=0\n",
    "FREQ=10000\n",
    "def rayProcessing(initial,nw=0):\n",
    "    global NRAYS,FREQ\n",
    "    t=initial[0]\n",
    "    site=initial[1]\n",
    "    direction=initial[2]\n",
    "    ray=GrtRay(site,direction[0][0],direction[0][1],direction[1])\n",
    "    ray.updateRay(t)\n",
    "    try:\n",
    "        ray.propagateRay(t)\n",
    "        detJ=ray.calcJacobianDeterminant()\n",
    "    except AssertionError as e:\n",
    "        detJ=0\n",
    "    raydf=ray.packRay()\n",
    "    raydf[\"detJ\"]=detJ\n",
    "    del ray\n",
    "    NRAYS+=1\n",
    "    if (NRAYS%FREQ)==1:\n",
    "        unreachable=gc.collect()\n",
    "        print(f\"Completed rays by worker {nw}: {NRAYS} (unreachable {unreachable})\")\n",
    "        elTime(start=True)\n",
    "    return raydf\n",
    "    \n",
    "def rayProcessingMulti(initials,nw=0):\n",
    "    print(f\"Processing {len(initials)} initial conditions in worker {nw}\")\n",
    "    raydfs=[rayProcessing(initial,nw=nw) for initial in initials]\n",
    "    return raydfs\n",
    "\n",
    "allrays=pd.DataFrame()\n",
    "def joinResults(raydfs):\n",
    "    global allrays\n",
    "    allrays=pd.concat((allrays,)+tuple(raydfs))\n",
    "    del raydfs\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts=[Spice.str2t(\"02/15/2013 03:20:34 UTC\")]\n",
    "siteprops=[[61.1*Angle.Deg,54.8*Angle.Deg,23.3*Const.km]]\n",
    "sites=[]\n",
    "for siteprop in siteprops:\n",
    "    sites+=[Location(body,siteprop[0],siteprop[1],siteprop[2])]\n",
    "directions=[[[101.1*Angle.Deg,15.9*Angle.Deg],-18.6*Const.km/Const.s]]\n",
    "\n",
    "#List of conditions\n",
    "initials=list(cartesian(*[ts,sites,directions]))\n",
    "r=rayProcessingMulti(initials)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r[0][['et','ximp', 'yimp', 'zimp','vximp', 'vyimp', 'vzimp']].values*np.array([1]+[1/1e3]*6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r[0][['q','e', 'i', 'W','w', 'M']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massive input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numbers\n",
    "Ntimes=Nsites=Npoints=Nvels=3\n",
    "\"\"\"\n",
    "Ntimes=365\n",
    "Nsites=100\n",
    "Npoints=100\n",
    "Nvels=50\n",
    "#\"\"\"\n",
    "\n",
    "#Times\n",
    "print(\"Preparing times...\")\n",
    "tini=Spice.str2t(\"02/15/2013 03:20:34\")\n",
    "tend=tini+Const.Year\n",
    "ts=np.linspace(tini,tend,10)\n",
    "\n",
    "#Sites\n",
    "print(\"Preparing sites...\")\n",
    "elTime(0)\n",
    "H=23.3*Const.km\n",
    "points=Sample(Nsites)\n",
    "points.genUnitSphere()\n",
    "siteprops=np.zeros((Nsites,3))\n",
    "siteprops[:,:2]=points.pp[:,1:]\n",
    "siteprops[:,2]=H*np.ones(Nsites)\n",
    "sites=[]\n",
    "for siteprop in siteprops:\n",
    "    sites+=[Location(body,siteprop[0],siteprop[1],siteprop[2])]\n",
    "elTime()\n",
    "\n",
    "#Directions\n",
    "print(\"Preparing directions...\")\n",
    "elTime(0)\n",
    "gpoints=Sample(Npoints)\n",
    "gpoints.genUnitHemisphere()\n",
    "speeds=-np.linspace(11.2,72.0,Nvels)*Const.km/Const.s\n",
    "directions=list(cartesian(*[gpoints.pp[:,1:].tolist(),speeds]))\n",
    "elTime()\n",
    "\n",
    "#Initial conditions\n",
    "print(\"Preparing initial conditions...\")\n",
    "elTime(0)\n",
    "initials=list(cartesian(*[ts,sites,directions]))\n",
    "elTime()\n",
    "\n",
    "Ninitials=len(initials)\n",
    "print(f\"Number of initial conditions: {Ninitials} = {len(ts)}(ts)*{len(sites)}(sites)*{len(directions)}(dirs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking and computing time estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing time estimations\n",
    "print(f\"Sequential processing of {Ninitials} rays:\")\n",
    "dt,dtu=elTime(0)\n",
    "tinitials=initials[:10]\n",
    "rays=rayProcessingMulti(tinitials)\n",
    "dt,dtu=elTime()\n",
    "tpray=dt/len(tinitials)\n",
    "tupray=tUnit(tpray)\n",
    "totrays=tpray*Ninitials\n",
    "toturays=tUnit(totrays)\n",
    "print(f\"Total duration: {dtu[0]} {dtu[1]}, Duration per ray: {tupray[0]} {tupray[1]}\")\n",
    "\n",
    "#Chunks\n",
    "npchunk=np.int(np.ceil(Ninitials/NP))\n",
    "cinitials=[initial for initial in Util.chunkList(initials,npchunk)]\n",
    "Nchunks=len(cinitials)\n",
    "FREQ=np.int(npchunk/10)\n",
    "print(f\"{Nchunks} chunks containing {npchunk} initial conditions (showed with frequency {FREQ})\")\n",
    "tchunk=tpray*npchunk\n",
    "tchunku=tUnit(tchunk)\n",
    "print()\n",
    "print(f\"Estimated total: {toturays[0]} {toturays[1]}\")\n",
    "\n",
    "print(f\"Estimated time per chunk (estimated parallel): {tchunku[0]} {tchunku[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allrays=pd.DataFrame()\n",
    "pool=mp.Pool(processes=NP)\n",
    "elTime(0)\n",
    "[pool.apply_async(rayProcessingMulti,args=(inis,nw),callback=joinResults) for nw,inis in enumerate(cinitials)]\n",
    "pool.close()\n",
    "pool.join()\n",
    "elTime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of results:\",len(allrays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allrays.to_csv(\"rays_parallel.csv\",index=False,float_format='%.17e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--End--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 730000 conditions...\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"../tmp/rays_parallel.csv.gz\",compression='gzip')\n",
    "del data['Unnamed: 0']\n",
    "print(f\"Read {len(data)} conditions...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(\"../tmp/rays_parallel.csv.gz\",compression='gzip',index=False,float_format='%.17e')\n",
    "#np.savetxt(\"../tmp/rays_parallel.dat\",data.values,fmt=\"%.17e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.24660448e+08 -1.23164974e+07 -1.51860159e+08 -9.61439193e+02\n",
      "   2.64288343e+01  6.65402372e+00 -5.82682421e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(test[['et','ximp', 'yimp', 'zimp','vximp', 'vyimp', 'vzimp']].values*np.array([1]+[1/1e3]*6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          q         e         i          W           w          M\n",
      "0  1.007315  3.561901  65.96306  85.363151  189.602713 -19.765144\n"
     ]
    }
   ],
   "source": [
    "print(test[['q','e', 'i', 'W','w', 'M']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 730000/730000 [15:29<00:00, 785.52it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time since last call: 15.4892 min\n"
     ]
    }
   ],
   "source": [
    "dt=elTime(0)\n",
    "f=open(\"../tmp/gravray-include.sh\",\"w\")\n",
    "empty=\"\"\n",
    "for i in range(10):empty+=f\"0\\t\"\n",
    "nrays=len(data)\n",
    "for i,index in enumerate(tqdm(data.index)):\n",
    "    ray=data.loc[index]\n",
    "    et=ray[\"et\"]\n",
    "    ximp=\"\"\n",
    "    for x in ray[['ximp','yimp','zimp','vximp','vyimp','vzimp']].values*np.array([1/1e3]*6):\n",
    "        ximp+=f\"{x:.17e} \"\n",
    "    f.write(f\"echo 'ray {i}/{nrays}...';\")\n",
    "    f.write(f\"rm ray$1.dat &> /dev/null;\")\n",
    "    f.write(f\"./wherewillitbe.exe {ray['et']:.17e} {ximp} -1.0 2 \\\"$1\\\" &> /dev/null;\")\n",
    "    f.write(f'if [ $? -eq 0 -a \"x$(cat ray$1.dat)\" != \"x\" ];then tail -n 1 ray$1.dat >> orbits$1.dat;')\n",
    "    f.write(f\"else echo '{et:+.17e} {ximp} {empty}' >> orbits$1.dat;\")\n",
    "    f.write(f\"fi\"+\"\\n\")\n",
    "f.close()\n",
    "dt=elTime(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
